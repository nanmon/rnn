{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal recurrente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = open(\"grimms.txt\", 'r', encoding='utf8').read()\n",
    "# nparray de palabras\n",
    "characters = list(set(dataset_train)) # debí ordenar esta cosa ;c\n",
    "char_to_index = { ch:i for i,ch in enumerate(characters) }\n",
    "index_to_char = { i:ch for i,ch in enumerate(characters) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 50\n",
    "VOCAB_SIZE = len(characters)\n",
    "N_SEQUENCES = int(len(dataset_train)/SEQ_LENGTH)\n",
    "HIDDEN_DIM = 700 # neuronas por capa\n",
    "LSTM_LAYERS = 3 # numero de capas\n",
    "DROPOUT_RATIO = 0.3 # dropout de la primera capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando la estructura de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((N_SEQUENCES, SEQ_LENGTH, VOCAB_SIZE))\n",
    "y_train = np.zeros((N_SEQUENCES, SEQ_LENGTH, VOCAB_SIZE))\n",
    "for i in range(0, N_SEQUENCES):\n",
    "    X_sequence = dataset_train[i*SEQ_LENGTH: (i+1)*SEQ_LENGTH]          # siguente texto de tamaño SEQ_LENGTH\n",
    "    X_sequence_index = [char_to_index[value] for value in X_sequence]   # mapeo a indices\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))                 # entrada a matriz de categorias\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_index[j]] = 1                      # probabilidad 1 al caracter dado\n",
    "    X_train[i] = input_sequence                                         # añadir a entradas del entrenamiento\n",
    "    \n",
    "    y_sequence = dataset_train[i*SEQ_LENGTH+1: (i+1)*SEQ_LENGTH+1]      # texto salida (shifteado uno a la derecha)\n",
    "    y_sequence_index = [char_to_index[value] for value in y_sequence]   # mapeo a indices\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))                # salida a matriz de categorias\n",
    "    for j in range(SEQ_LENGTH):                                         \n",
    "        target_sequence[j][y_sequence_index[j]] = 1                     # probabilidad 1 al caracter dado\n",
    "    y_train[i] = target_sequence                                        # añadir a salidas del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo la red neuronal recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, TimeDistributed, Activation\n",
    "\n",
    "def build_rnn():\n",
    "    # Inicializando la red\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Añadiendo la primera LSTM\n",
    "    model.add(LSTM(\n",
    "        units = HIDDEN_DIM, \n",
    "        return_sequences = True,             # Pasa las secuencias a la siguiente capa encolada LSTM\n",
    "        input_shape = (None, VOCAB_SIZE)     # Tamaño de la entrada\n",
    "    ))\n",
    "    model.add(Dropout(DROPOUT_RATIO))\n",
    "    \n",
    "    for i in range(LSTM_LAYERS - 1):\n",
    "        #Añadiendo las demas LSTM\n",
    "        model.add(LSTM(\n",
    "            units = HIDDEN_DIM, \n",
    "            return_sequences = True\n",
    "        ))\n",
    "    model.add(TimeDistributed(Dense(VOCAB_SIZE)))   # Combina las LSTM para ser compatible con una salida softmax\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    # Compilando la red\n",
    "    model.compile(\n",
    "        optimizer = 'rmsprop', \n",
    "        loss = 'categorical_crossentropy'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/140\n",
      "10352/10352 [==============================] - 327s - loss: 0.4452   \n",
      "Epoch 2/140\n",
      "10352/10352 [==============================] - 377s - loss: 0.4065   \n",
      "Epoch 3/140\n",
      "10352/10352 [==============================] - 378s - loss: 0.3735   \n",
      "Epoch 4/140\n",
      "10352/10352 [==============================] - 346s - loss: 0.3468   \n",
      "Epoch 5/140\n",
      "10352/10352 [==============================] - 364s - loss: 0.3267   \n",
      "Epoch 6/140\n",
      "10352/10352 [==============================] - 378s - loss: 0.3101   \n",
      "Epoch 7/140\n",
      "10352/10352 [==============================] - 367s - loss: 0.2966   \n",
      "Epoch 8/140\n",
      "10352/10352 [==============================] - 347s - loss: 0.2860   \n",
      "Epoch 9/140\n",
      "10352/10352 [==============================] - 380s - loss: 0.2773   \n",
      "Epoch 10/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2703   \n",
      "Epoch 11/140\n",
      "10352/10352 [==============================] - 330s - loss: 0.2635   \n",
      "Epoch 12/140\n",
      "10352/10352 [==============================] - 378s - loss: 0.2593   \n",
      "Epoch 13/140\n",
      "10352/10352 [==============================] - 377s - loss: 0.2552   \n",
      "Epoch 14/140\n",
      "10352/10352 [==============================] - 335s - loss: 0.2520   \n",
      "Epoch 15/140\n",
      "10352/10352 [==============================] - 370s - loss: 0.2480   \n",
      "Epoch 16/140\n",
      "10352/10352 [==============================] - 385s - loss: 0.2462   \n",
      "Epoch 17/140\n",
      "10352/10352 [==============================] - 355s - loss: 0.2434   \n",
      "Epoch 18/140\n",
      "10352/10352 [==============================] - 359s - loss: 0.2409   \n",
      "Epoch 19/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2399   \n",
      "Epoch 20/140\n",
      "10352/10352 [==============================] - 371s - loss: 0.2382   \n",
      "Epoch 21/140\n",
      "10352/10352 [==============================] - 341s - loss: 0.2367   \n",
      "Epoch 22/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2339   \n",
      "Epoch 23/140\n",
      "10352/10352 [==============================] - 380s - loss: 0.2337   \n",
      "Epoch 24/140\n",
      "10352/10352 [==============================] - 338s - loss: 0.2321   \n",
      "Epoch 25/140\n",
      "10352/10352 [==============================] - 374s - loss: 0.2310   \n",
      "Epoch 26/140\n",
      "10352/10352 [==============================] - 378s - loss: 0.2301   \n",
      "Epoch 27/140\n",
      "10352/10352 [==============================] - 379s - loss: 0.2296   \n",
      "Epoch 28/140\n",
      "10352/10352 [==============================] - 334s - loss: 0.2277   \n",
      "Epoch 29/140\n",
      "10352/10352 [==============================] - 372s - loss: 0.2274   \n",
      "Epoch 30/140\n",
      "10352/10352 [==============================] - 380s - loss: 0.2257   \n",
      "Epoch 31/140\n",
      "10352/10352 [==============================] - 348s - loss: 0.2260   \n",
      "Epoch 32/140\n",
      "10352/10352 [==============================] - 362s - loss: 0.2256   \n",
      "Epoch 33/140\n",
      "10352/10352 [==============================] - 384s - loss: 0.2243   \n",
      "Epoch 34/140\n",
      "10352/10352 [==============================] - 365s - loss: 0.2236   \n",
      "Epoch 35/140\n",
      "10352/10352 [==============================] - 338s - loss: 0.2232   \n",
      "Epoch 36/140\n",
      "10352/10352 [==============================] - 383s - loss: 0.2221   \n",
      "Epoch 37/140\n",
      "10352/10352 [==============================] - 380s - loss: 0.2224   \n",
      "Epoch 38/140\n",
      "10352/10352 [==============================] - 330s - loss: 0.2215   \n",
      "Epoch 39/140\n",
      "10352/10352 [==============================] - 377s - loss: 0.2219   \n",
      "Epoch 40/140\n",
      "10352/10352 [==============================] - 376s - loss: 0.2207   \n",
      "Epoch 41/140\n",
      "10352/10352 [==============================] - 340s - loss: 0.2210   \n",
      "Epoch 42/140\n",
      "10352/10352 [==============================] - 368s - loss: 0.2202   \n",
      "Epoch 43/140\n",
      "10352/10352 [==============================] - 385s - loss: 0.2203   \n",
      "Epoch 44/140\n",
      "10352/10352 [==============================] - 358s - loss: 0.2194   \n",
      "Epoch 45/140\n",
      "10352/10352 [==============================] - 354s - loss: 0.2184   \n",
      "Epoch 46/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2189   \n",
      "Epoch 47/140\n",
      "10352/10352 [==============================] - 374s - loss: 0.2188   \n",
      "Epoch 48/140\n",
      "10352/10352 [==============================] - 336s - loss: 0.2181   \n",
      "Epoch 49/140\n",
      "10352/10352 [==============================] - 379s - loss: 0.2183   \n",
      "Epoch 50/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2178   \n",
      "Epoch 51/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2172   \n",
      "Epoch 52/140\n",
      "10352/10352 [==============================] - 385s - loss: 0.2175   \n",
      "Epoch 53/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2171   \n",
      "Epoch 54/140\n",
      "10352/10352 [==============================] - 379s - loss: 0.2176   \n",
      "Epoch 55/140\n",
      "10352/10352 [==============================] - 383s - loss: 0.2169   \n",
      "Epoch 56/140\n",
      "10352/10352 [==============================] - 379s - loss: 0.2168   \n",
      "Epoch 57/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2166   \n",
      "Epoch 58/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2172   \n",
      "Epoch 59/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2166   \n",
      "Epoch 60/140\n",
      "10352/10352 [==============================] - 383s - loss: 0.2161   \n",
      "Epoch 61/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2159   \n",
      "Epoch 62/140\n",
      "10352/10352 [==============================] - 385s - loss: 0.2165   \n",
      "Epoch 63/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2165   \n",
      "Epoch 64/140\n",
      "10352/10352 [==============================] - 379s - loss: 0.2162   \n",
      "Epoch 65/140\n",
      "10352/10352 [==============================] - 381s - loss: 0.2156   \n",
      "Epoch 66/140\n",
      "10352/10352 [==============================] - 377s - loss: 0.2151   \n",
      "Epoch 67/140\n",
      "10352/10352 [==============================] - 383s - loss: 0.2153   \n",
      "Epoch 68/140\n",
      "10352/10352 [==============================] - 382s - loss: 0.2151   \n",
      "Epoch 69/140\n",
      "10352/10352 [==============================] - 383s - loss: 0.2151   \n",
      "Epoch 70/140\n",
      "10336/10352 [============================>.] - ETA: 0s - loss: 0.2148"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't decrement id ref count (unable to extend file properly)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    175\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                             \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dwrite\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't prepare for writing data (file write failed: time = Thu Dec 14 03:36:37 2017\n, filename = 'ckpt/seq50/weightsv2.69-0.21.hdf5', file descriptor = 4, errno = 28, error message = 'No space left on device', buf = 000001985BE7E040, total write size = 7840000, bytes this sub-write = 7840000, bytes actually written = 18446744073709551615, offset = 64694712)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-311d6dfa69be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ckpt/seq50/weights.14-0.49.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m140\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1201\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    426\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   2551\u001b[0m         \"\"\"\n\u001b[0;32m   2552\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2553\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    175\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                             \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nn\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mid_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                     \u001b[1;32mwhile\u001b[0m \u001b[0mid_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                         \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_ref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5i.pyx\u001b[0m in \u001b[0;36mh5py.h5i.dec_ref\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't decrement id ref count (unable to extend file properly)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = \"ckpt/seq50/weightsv2.{epoch:02d}-{loss:.2f}.hdf5\",\n",
    "    monitor = \"loss\",\n",
    "    period = 5\n",
    ")\n",
    "\n",
    "# model = build_rnn()\n",
    "# Cargando desde otro checkpoint donde cancelé el entrenamiento porque quería ver algo (8\n",
    "model = load_model(\"ckpt/seq50/weights.14-0.49.hdf5\")\n",
    "history = model.fit(X_train, y_train, epochs = 140, batch_size = 32, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando ultimo modelo\n",
    "Primero entrene con secuencias de 200 caracteres con 100 epochs todo el día, al volver del trabajo resulta que se había muerto el proceso de python, así que tuve que volver a empezar, pero ahora si le puse checkpoints. A la mitad de la noche se reinició la compu porque tenía actualizaciones y solo llegó a guardar el epoch 60, y dado que no tomé en cuenta el orden del mapeo de caracteres, practicamente volví a empezar. Volvió a entrenar otros 60 epochs, pero me di cuenta que los resultados no eran muy buenos, prácticamente copiaba enunciados completos. Hice otro entrenamiento con secuencias de 50 caracteres y llegó a los 65 epochs porque se me acabó el espacio en disco. Los resultados no son muy coherentes pero estoy conforme y corto de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando modelo con secuencias de 50 caracteres, epoch 65\n",
    "model = load_model(\"ckpt/seq50/weightsv2.64-0.22.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ‘What do you want here?--speak off!’ said the cat quite as my little mother\n",
      "has come home, and has brought you her finger; but the wild man was standing at the hills, into the bed with the\n",
      "eggs that sprinkled for joy. At last he could bear it no longer; so he gave him a needle, and drew the turnip to the court that was left all that sick up the castle was called Snow-white, and\n",
      "the star-gazer took his glass, looked up, and said, ‘Now, my\n",
      "godden a fellow who will see mine.’ Then the king and mo"
     ]
    }
   ],
   "source": [
    "length = 500\n",
    "\n",
    "ix = [np.random.randint(VOCAB_SIZE)]                      # caracter random\n",
    "y_char = [index_to_char[ix[-1]]]                          # salida que no se usa para nada\n",
    "X = np.zeros((1, length, VOCAB_SIZE))                     # Matriz tridimensional de entrada\n",
    "for i in range(length): \n",
    "    X[0, i, :][ix[-1]] = 1                                # Añade el ultimo caracter a la entrada\n",
    "    print(index_to_char[ix[-1]], end=\"\")                  # Imprime el ultimo caracter\n",
    "    ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)    # Predice las probabilidades para cada caracter y toma la mayor\n",
    "    y_char.append(index_to_char[ix[-1]])                  # Añade caracter predecido a la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
